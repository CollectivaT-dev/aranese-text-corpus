{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dc6c8d6",
   "metadata": {},
   "source": [
    "# Web to text corpus full pipeline\n",
    "\n",
    "This notebook processes publications published in the [Premsa Aranesa repository](https://ddd.uab.cat/collection/honsaran) to obtain a sentence segmented text corpus. \n",
    "\n",
    "The processes involved are:\n",
    "\n",
    "1. Parse the pages of publication record URL (e.g. https://ddd.uab.cat/record/218748) list specified in a text file. \n",
    "2. Download all associated PDFs\n",
    "3. Extract each page in the PDF as an image\n",
    "4. Perform optical character recognition (OCR) using Tesseract\n",
    "5. Correct ortographic and formatting errors using Claude LLM (needs API key but can be skipped also)\n",
    "6. Extract sentences from each document, save them for each publication and merge them into a single corpus file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4a9ca4",
   "metadata": {},
   "source": [
    "## Download PDFs and create download_summary.JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15fa842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dba5fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_links(url, doc_limit=None):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve the page: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    pdf_links = []\n",
    "\n",
    "    for link in soup.find_all('a', href=True):\n",
    "        href = link['href']\n",
    "        if '.pdf' in href:\n",
    "            pdf_links.append(href)\n",
    "\n",
    "    pdf_links = [requests.compat.urljoin(url, link) for link in pdf_links]\n",
    "    \n",
    "    if doc_limit:\n",
    "        pdf_links = pdf_links[0:doc_limit]\n",
    "        print(\"Processing only\", doc_limit, \"documents!\")\n",
    "\n",
    "    return pdf_links\n",
    "\n",
    "def get_publication_name(soup):\n",
    "    meta_tag = soup.find('meta', {'name': 'dc.title'})\n",
    "    if meta_tag and 'content' in meta_tag.attrs:\n",
    "        return meta_tag['content']\n",
    "    return \"Unknown_Publication\"\n",
    "\n",
    "def extract_id_from_url(url):\n",
    "    parts = url.split('/')\n",
    "    if len(parts) > 5:\n",
    "        return parts[5]\n",
    "    return \"Unknown_ID\"\n",
    "\n",
    "def download_pdfs(pdf_links, directory, max_retries=3, wait_time=2):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    downloaded_files = []\n",
    "    no_already_downloaded = 0\n",
    "    no_new_download = 0\n",
    "    no_failed_download = 0\n",
    "        \n",
    "    for link in pdf_links:\n",
    "        file_name = os.path.join(directory, os.path.basename(link))\n",
    "        if os.path.exists(file_name):\n",
    "#             print(f\"Already downloaded: {file_name}\")\n",
    "            downloaded_files.append(file_name)\n",
    "            no_already_downloaded += 1\n",
    "            continue\n",
    "\n",
    "        success = False\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = requests.get(link)\n",
    "                if response.status_code == 200:\n",
    "                    with open(file_name, 'wb') as f:\n",
    "                        f.write(response.content)\n",
    "                    downloaded_files.append(file_name)\n",
    "#                     print(f\"Downloaded: {file_name}\")\n",
    "                    success = True\n",
    "                    no_new_downloaded += 1\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"Failed to download: {link} (status code: {response.status_code})\")\n",
    "            except requests.RequestException as e:\n",
    "                print(f\"Attempt {attempt + 1} failed with error: {e}\")\n",
    "            \n",
    "            if not success:\n",
    "                print(f\"Retrying in {wait_time} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "\n",
    "        if not success:\n",
    "            print(f\"Failed to download: {link} after {max_retries} attempts\")\n",
    "            no_failed_download += 1\n",
    "            \n",
    "    print(f\"{no_new_download} new, {no_already_downloaded} already downloaded\")\n",
    "    if no_failed_download:\n",
    "        print(f\"{no_failed_download} failed to download\")\n",
    "\n",
    "    return downloaded_files\n",
    "\n",
    "def process_repository_links(file_path, doc_limit=None):\n",
    "    results = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        urls = [line.strip() for line in file if line.strip()]\n",
    "\n",
    "    for url in urls:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to retrieve the page: {response.status_code} for URL: {url}\")\n",
    "            continue\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        publication_name = get_publication_name(soup)\n",
    "        print(publication_name)\n",
    "        \n",
    "        pdf_links = extract_pdf_links(url, doc_limit)\n",
    "        print(len(pdf_links), \"documents\")\n",
    "        \n",
    "        publication_id = extract_id_from_url(pdf_links[0])\n",
    "        \n",
    "        if pdf_links:\n",
    "            directory = os.path.join(\"docs\", publication_id)\n",
    "            pdf_directory = os.path.join(directory, \"pdf\")\n",
    "            downloaded_files = download_pdfs(pdf_links, pdf_directory)\n",
    "            results.append({\n",
    "                \"name\": publication_name,\n",
    "                \"id\": publication_id,\n",
    "                \"url\": url,\n",
    "                \"directory\": directory,\n",
    "                \"no_docs\": len(downloaded_files),\n",
    "                \"docs\" : sorted(downloaded_files)\n",
    "            })\n",
    "        else:\n",
    "            print(f\"No PDF links found for URL: {url}\")\n",
    "\n",
    "    # Write results to JSON file with proper encoding for non-ASCII characters\n",
    "    with open(os.path.join(\"docs\", \"download_summary.json\"), 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"Download summary written to {os.path.join('docs', 'download_summary.json')}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17149f39",
   "metadata": {},
   "source": [
    "### Download PDFs from publication URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "db4de575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vielha de toti : era revista dera gent de Vielha e Mijaran\n",
      "2 documents\n",
      "0 new, 2 already downloaded\n",
      "Aran un país\n",
      "1 documents\n",
      "0 new, 1 already downloaded\n",
      "Aué : suplement setmanau deth diari Avui\n",
      "165 documents\n",
      "0 new, 165 already downloaded\n",
      "Download summary written to docs/download_summary.json\n"
     ]
    }
   ],
   "source": [
    "file_path = \"uab_repo_urls_3.txt\"\n",
    "download_summary = process_repository_links(file_path, doc_limit=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43389051",
   "metadata": {},
   "source": [
    "#### Run the cell below if reading download_summary.JSON from disk (skipping the cell above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7caaf6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 records\n"
     ]
    }
   ],
   "source": [
    "with open('docs/download_summary_3.json', 'r') as f:\n",
    "    download_summary = json.load(f)\n",
    "\n",
    "# Now download_summary is available for use\n",
    "print(len(download_summary), \"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9ce4b6",
   "metadata": {},
   "source": [
    "## Image extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c068f5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import time\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f66c407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert PDF to images\n",
    "def pdf_to_images(pdf_path):\n",
    "    try:\n",
    "        images = convert_from_path(pdf_path)\n",
    "        return images\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting {pdf_path} to images: {e}\")\n",
    "        return []\n",
    "\n",
    "# Function to save images to files with resolution check\n",
    "def save_image(image, image_path):\n",
    "    try:\n",
    "        buffer = io.BytesIO()\n",
    "        image.save(buffer, format=\"PNG\")\n",
    "        file_size = buffer.tell()\n",
    "\n",
    "        with open(image_path, 'wb') as f:\n",
    "            f.write(buffer.getvalue())\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving image to {image_path}: {e}\")\n",
    "\n",
    "def extract_images_from_documents(download_summary, overwrite_imgs=False):\n",
    "    total_no_images = 0\n",
    "    total_saved_images = 0\n",
    "    \n",
    "    for pub in download_summary:\n",
    "        print(pub['name'])\n",
    "\n",
    "        for doc_path in pub['docs']:\n",
    "            doc_name = doc_path.split('/')[-1]\n",
    "            print(doc_name, end=\" - \")\n",
    "\n",
    "            imgs_dir = os.path.join(pub['directory'], 'img', doc_name)\n",
    "\n",
    "            os.makedirs(imgs_dir, exist_ok=True)\n",
    "\n",
    "            # Check if the image directory is empty\n",
    "            ls_imgs_dir = [i for i in os.listdir(imgs_dir) if not i==\".DS_Store\" ]\n",
    "            if not overwrite_imgs and ls_imgs_dir:\n",
    "                print(\"✔️\")\n",
    "                total_no_images += len(ls_imgs_dir)\n",
    "                continue\n",
    "        \n",
    "            # Extract images from pdf\n",
    "            images = pdf_to_images(doc_path)\n",
    "            print(\"✅\", len(images), \"images\", end=\" \")\n",
    "            \n",
    "            # Save images in parallel\n",
    "            def save_image_task(args):\n",
    "                image, image_path = args\n",
    "                save_image(image, image_path)\n",
    "\n",
    "            with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "                future_to_image = {executor.submit(save_image_task, (image, os.path.join(imgs_dir, f\"page_{i + 1}.png\"))): i for i, image in enumerate(images)}\n",
    "                for future in concurrent.futures.as_completed(future_to_image):\n",
    "                    total_saved_images += 1\n",
    "                    total_no_images += 1\n",
    "                    \n",
    "            print(\"saved\")\n",
    "\n",
    "        print()\n",
    "            \n",
    "    print(total_no_images, \"images in total from\", len(download_summary), \"documents\")\n",
    "    print(total_saved_images, \"new saved\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a774d3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======Converting each pdf into images=======\n",
      "Aué : suplement setmanau deth diari Avui\n",
      "aueavui_a2004m1d31.pdf - ✅ 4 images saved\n",
      "aueavui_a2004m2d14.pdf - ✅ 4 images saved\n",
      "aueavui_a2004m2d21.pdf - ✅ 4 images saved\n",
      "aueavui_a2004m2d28.pdf - ✅ 4 images saved\n",
      "aueavui_a2004m2d7.pdf - ✅ 4 images saved\n",
      "\n",
      "20 images in total from 1 documents\n",
      "20 new saved\n",
      "Elapsed time: 15.190072059631348 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"=======Converting each pdf into images=======\")\n",
    "\n",
    "# Start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Convert each pdf into images\n",
    "extract_images_from_documents(download_summary, overwrite_imgs=False) ## overwrite_imgs True for debugging\n",
    "\n",
    "# End time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Elapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4536dc2",
   "metadata": {},
   "source": [
    "### Tesseract OCR + post-editing with Anthropic API\n",
    "\n",
    "Reminder: Place the anthropic API key into `.env` file as in\n",
    "\n",
    "```\n",
    "ANTHROPIC_API_KEY=your_api_key_here\n",
    "```\n",
    "\n",
    "Correction step can be skipped with flag `skip_correction` when calling `do_ocr_and_fix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1799d66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "import re\n",
    "\n",
    "#Setup language for Tesseract\n",
    "LANG = \"oci\"\n",
    "\n",
    "# Function to perform OCR on an image\n",
    "def ocr_image_to_text(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        text = pytesseract.image_to_string(image, lang=LANG)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️Error during OCR for {image_path}⚠️: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c590b9eb",
   "metadata": {},
   "source": [
    "#### Note: Correction step can be skipped. Don't execute cell below if so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7a6b9e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "import io\n",
    "import re\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from environment variable\n",
    "api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "\n",
    "if api_key is None:\n",
    "    raise ValueError(\"No API key found. Please set the ANTHROPIC_API_KEY environment variable.\")\n",
    "\n",
    "anthropic_client = anthropic.Anthropic()\n",
    "\n",
    "instructions_detailed = (\n",
    "    \"You are tasked with fixing OCR output text in Aranese, respecting Aranese orthography, merging lines where necessary, \"\n",
    "    \"and producing a proper output. This task is crucial for preserving the integrity and readability of the material and \"\n",
    "    \"create a large text corpus for this language.\\n\\n\"\n",
    "\n",
    "    \"Follow these steps to process the text:\\n\\n\"\n",
    "\n",
    "    \"0. Only output the corrected text, without any introductory or additional phrases.\\n\\n\"\n",
    "\n",
    "    \"1. Analyze and correct Occitan Aranese characters and diacritical marks:\\n\"\n",
    "    \"   - Pay close attention to special characters and diacritical marks (e.g., à, è, ò, ï, ü).\\n\"\n",
    "    \"   - Ensure accurate spelling according to Occitan Aranese conventions.\\n\\n\"\n",
    "\n",
    "    \"2. Maintain sentence integrity:\\n\"\n",
    "    \"   - Examine each line to determine if it's a complete sentence or part of a continuing sentence.\\n\"\n",
    "    \"   - Join continuing sentences even if they span multiple lines visually.\\n\"\n",
    "    \"   - Look for grammatical clues such as:\\n\"\n",
    "    \"     a. Lack of final punctuation at the end of a line\\n\"\n",
    "    \"     b. Lines beginning with lowercase letters (unless it's a language-specific exception)\\n\"\n",
    "    \"     c. Incomplete grammatical structures that continue on the next line\\n\\n\"\n",
    "\n",
    "    \"3. Address justified paragraphs and hyphens:\\n\"\n",
    "    \"   - Remove hyphens within words that are divided across lines in justified text.\\n\"\n",
    "    \"   - Rejoin hyphenated words, placing the complete word at the end of the first line.\\n\"\n",
    "    \"   - Ensure that removing hyphens doesn't create unintended new words.\\n\\n\"\n",
    "\n",
    "    \"4. Preserve paragraph structure:\\n\"\n",
    "    \"   - Maintain paragraph breaks as they appear in the original text.\\n\"\n",
    "    \"   - Represent each new paragraph as a new line in the output.\\n\\n\"\n",
    "\n",
    "    \"5. Handle titles and headings:\\n\"\n",
    "    \"   - Preserve titles and headings as separate lines in the output.\\n\"\n",
    "    \"   - Do not join titles or headings with the following paragraph text.\\n\\n\"\n",
    "\n",
    "    \"6. Perform a final verification:\\n\"\n",
    "    \"   - Review the processed text to ensure:\\n\"\n",
    "    \"     a. All sentences are intact and properly joined.\\n\"\n",
    "    \"     b. Paragraphs and titles are correctly separated.\\n\"\n",
    "    \"     c. No artifacts from visual formatting remain.\\n\"\n",
    "    \"   - Double-check that the Occitan Aranese orthography is correctly preserved throughout.\"\n",
    ")\n",
    "\n",
    "# Function to fix OCR text with the API\n",
    "def fix_ocr_text_with_api(ocr_text):\n",
    "    try:\n",
    "        message = anthropic_client.messages.create(\n",
    "            model=\"claude-3-5-sonnet-20240620\",\n",
    "            max_tokens=4096,\n",
    "            temperature=0,\n",
    "            system=instructions_detailed,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": ocr_text\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        return message.content[0].text\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️Error during API call⚠️: {e}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "eecac83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform OCR and correction for a single image\n",
    "def process_image(args, skip_correction=False):\n",
    "    img_path, ocr_path, fix_path = args\n",
    "    ocr_status = fix_status = \"✔️\"\n",
    "\n",
    "    try:\n",
    "        # Perform OCR if the OCR text file does not exist\n",
    "        if not os.path.isfile(ocr_path):\n",
    "            OCR_text = ocr_image_to_text(img_path)\n",
    "            if OCR_text:\n",
    "                with open(ocr_path, 'w') as f:\n",
    "                    f.write(OCR_text)\n",
    "                ocr_status = \"✅\"\n",
    "            else:\n",
    "                ocr_status = \"❌\"\n",
    "        else:\n",
    "            with open(ocr_path, 'r') as f:\n",
    "                OCR_text = f.read()\n",
    "\n",
    "        # Now send to Anthropic API to fix or do manual fixing\n",
    "        if OCR_text and not os.path.isfile(fix_path):\n",
    "            if skip_correction:\n",
    "                fixed_text = OCR_text\n",
    "            else:\n",
    "                fixed_text = fix_ocr_text_with_api(OCR_text)\n",
    "            \n",
    "            if fixed_text:\n",
    "                # Write fixed OCR text to file\n",
    "                with open(fix_path, 'w') as f:\n",
    "                    f.write(fixed_text)\n",
    "                fix_status = \"✅\"\n",
    "            else:\n",
    "                fix_status = \"❌\"\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_path}: {e}\")\n",
    "\n",
    "    return img_path, ocr_status, fix_status\n",
    "\n",
    "# Process to perform OCR and correct\n",
    "def do_ocr_and_fix(download_summary, skip_correction=False):\n",
    "    for pub in download_summary:\n",
    "        print(pub['name'])\n",
    "\n",
    "        imgs_dir = os.path.join(pub['directory'], 'img')\n",
    "\n",
    "        ocr_dir = os.path.join(pub['directory'], 'ocr')\n",
    "        os.makedirs(ocr_dir, exist_ok=True)\n",
    "\n",
    "        fix_dir = os.path.join(pub['directory'], 'fix')\n",
    "        os.makedirs(fix_dir, exist_ok=True)\n",
    "        \n",
    "        # Do a count of all images to process\n",
    "        no_images_processed = 0\n",
    "        pub_img_count = sum([len([img_name for img_name in os.listdir(os.path.join(imgs_dir, doc_name)) if img_name.endswith(('.png'))]) for doc_name in os.listdir(imgs_dir) if os.path.isdir(os.path.join(imgs_dir, doc_name))])\n",
    "        print(pub_img_count, \"pages to process in publication\\n\")\n",
    "        \n",
    "        # Iterate over each document in the publication\n",
    "        for doc_name in sorted(os.listdir(imgs_dir)):\n",
    "            doc_img_dir = os.path.join(imgs_dir, doc_name)\n",
    "            doc_ocr_dir = os.path.join(ocr_dir, doc_name)\n",
    "            doc_fix_dir = os.path.join(fix_dir, doc_name)\n",
    "\n",
    "            # Skip non-directory files\n",
    "            if not os.path.isdir(doc_img_dir):\n",
    "                continue\n",
    "\n",
    "            print(\"-\", doc_name)\n",
    "\n",
    "            # Ensure the ocr and fix subdirectory for the document exists\n",
    "            os.makedirs(doc_ocr_dir, exist_ok=True)\n",
    "            os.makedirs(doc_fix_dir, exist_ok=True)\n",
    "\n",
    "            # List all images in the document's image directory\n",
    "            image_tasks = []\n",
    "            for img_name in sorted(os.listdir(doc_img_dir)):\n",
    "                img_path = os.path.join(doc_img_dir, img_name)\n",
    "                ocr_path = os.path.join(doc_ocr_dir, os.path.splitext(img_name)[0] + '.txt')\n",
    "                fix_path = os.path.join(doc_fix_dir, os.path.splitext(img_name)[0] + '.txt')\n",
    "\n",
    "                if os.path.isfile(img_path) and img_path.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    image_tasks.append((img_path, ocr_path, fix_path))\n",
    "\n",
    "            # Process images in parallel\n",
    "            with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "                futures = {executor.submit(process_image, task, skip_correction): task for task in image_tasks}\n",
    "                for future in concurrent.futures.as_completed(futures):\n",
    "                    img_path, ocr_status, fix_status = future.result()\n",
    "                    img_name = os.path.basename(img_path)\n",
    "                    no_images_processed += 1\n",
    "                    print(f\"-- {img_name} OCR{ocr_status} FIX{fix_status}\")\n",
    "\n",
    "            print(f\"- {no_images_processed}/{pub_img_count} processed\\n\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "89fa46a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========Performing OCR and correction===========\n",
      "Vielha de toti : era revista dera gent de Vielha e Mijaran\n",
      "15 pages to process in publication\n",
      "\n",
      "- vietot_a2017n1.pdf\n",
      "-- page_11.png OCR✔️ FIX✔️\n",
      "-- page_12.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_13.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 6/15 processed\n",
      "\n",
      "- vietot_a2018n3.pdf\n",
      "-- page_12.png OCR✔️ FIX✔️\n",
      "-- page_10.png OCR✔️ FIX✔️\n",
      "-- page_11.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "-- page_16.png OCR✔️ FIX✔️\n",
      "-- page_9.png OCR✔️ FIX✔️\n",
      "- 15/15 processed\n",
      "\n",
      "Aran un país\n",
      "8 pages to process in publication\n",
      "\n",
      "- arapai_a2019n1.pdf\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 8/8 processed\n",
      "\n",
      "Aué : suplement setmanau deth diari Avui\n",
      "891 pages to process in publication\n",
      "\n",
      "- aueavui_a1998m10d10.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "- 8/891 processed\n",
      "\n",
      "- aueavui_a1998m10d24.pdf\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "- 16/891 processed\n",
      "\n",
      "- aueavui_a1998m10d3.pdf\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "- 24/891 processed\n",
      "\n",
      "- aueavui_a1998m10d31.pdf\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 32/891 processed\n",
      "\n",
      "- aueavui_a1998m11d14.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 40/891 processed\n",
      "\n",
      "- aueavui_a1998m11d21.pdf\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 48/891 processed\n",
      "\n",
      "- aueavui_a1998m11d28.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "- 56/891 processed\n",
      "\n",
      "- aueavui_a1998m11d7.pdf\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 64/891 processed\n",
      "\n",
      "- aueavui_a1998m12d12.pdf\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "- 67/891 processed\n",
      "\n",
      "- aueavui_a1998m12d19.pdf\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "- 75/891 processed\n",
      "\n",
      "- aueavui_a1998m12d5.pdf\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "- 83/891 processed\n",
      "\n",
      "- aueavui_a1998m3d14.pdf\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 91/891 processed\n",
      "\n",
      "- aueavui_a1998m3d21.pdf\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "- 95/891 processed\n",
      "\n",
      "- aueavui_a1998m3d28.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "- 99/891 processed\n",
      "\n",
      "- aueavui_a1998m3d7.pdf\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_10.png OCR✔️ FIX✔️\n",
      "-- page_11.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_12.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "-- page_9.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "- 111/891 processed\n",
      "\n",
      "- aueavui_a1998m4d11.pdf\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "- 115/891 processed\n",
      "\n",
      "- aueavui_a1998m4d18.pdf\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 123/891 processed\n",
      "\n",
      "- aueavui_a1998m4d25.pdf\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "- 131/891 processed\n",
      "\n",
      "- aueavui_a1998m4d4.pdf\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "- 135/891 processed\n",
      "\n",
      "- aueavui_a1998m5d16.pdf\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 143/891 processed\n",
      "\n",
      "- aueavui_a1998m5d2.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "- 151/891 processed\n",
      "\n",
      "- aueavui_a1998m5d23.pdf\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "- 159/891 processed\n",
      "\n",
      "- aueavui_a1998m5d30.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "- 167/891 processed\n",
      "\n",
      "- aueavui_a1998m5d9.pdf\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 175/891 processed\n",
      "\n",
      "- aueavui_a1998m6d13.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "- 183/891 processed\n",
      "\n",
      "- aueavui_a1998m6d20.pdf\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 191/891 processed\n",
      "\n",
      "- aueavui_a1998m6d27.pdf\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "- 199/891 processed\n",
      "\n",
      "- aueavui_a1998m6d6.pdf\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "- 207/891 processed\n",
      "\n",
      "- aueavui_a1998m7d11.pdf\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "- 215/891 processed\n",
      "\n",
      "- aueavui_a1998m7d18.pdf\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "- 223/891 processed\n",
      "\n",
      "- aueavui_a1998m7d25.pdf\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "- 230/891 processed\n",
      "\n",
      "- aueavui_a1998m7d4.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 238/891 processed\n",
      "\n",
      "- aueavui_a1998m9d12.pdf\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 246/891 processed\n",
      "\n",
      "- aueavui_a1998m9d19.pdf\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 254/891 processed\n",
      "\n",
      "- aueavui_a1998m9d26.pdf\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 262/891 processed\n",
      "\n",
      "- aueavui_a1998m9d5.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "- 270/891 processed\n",
      "\n",
      "- aueavui_a1999m1d16.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 278/891 processed\n",
      "\n",
      "- aueavui_a1999m1d2.pdf\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "- 286/891 processed\n",
      "\n",
      "- aueavui_a1999m1d23.pdf\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 294/891 processed\n",
      "\n",
      "- aueavui_a1999m1d30.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 302/891 processed\n",
      "\n",
      "- aueavui_a1999m1d9.pdf\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "- 310/891 processed\n",
      "\n",
      "- aueavui_a1999m2d13.pdf\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "- 318/891 processed\n",
      "\n",
      "- aueavui_a1999m2d20.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 326/891 processed\n",
      "\n",
      "- aueavui_a1999m2d27.pdf\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 334/891 processed\n",
      "\n",
      "- aueavui_a1999m2d6.pdf\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "- 342/891 processed\n",
      "\n",
      "- aueavui_a1999m3d13.pdf\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 350/891 processed\n",
      "\n",
      "- aueavui_a1999m3d20.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 358/891 processed\n",
      "\n",
      "- aueavui_a1999m3d27.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "- 366/891 processed\n",
      "\n",
      "- aueavui_a1999m3d6.pdf\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "- 374/891 processed\n",
      "\n",
      "- aueavui_a1999m4d10.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 382/891 processed\n",
      "\n",
      "- aueavui_a1999m4d17.pdf\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 390/891 processed\n",
      "\n",
      "- aueavui_a1999m4d24.pdf\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 398/891 processed\n",
      "\n",
      "- aueavui_a1999m4d3.pdf\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 406/891 processed\n",
      "\n",
      "- aueavui_a1999m5d1.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 414/891 processed\n",
      "\n",
      "- aueavui_a1999m5d15.pdf\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 422/891 processed\n",
      "\n",
      "- aueavui_a1999m5d22.pdf\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 430/891 processed\n",
      "\n",
      "- aueavui_a1999m5d29.pdf\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "- 438/891 processed\n",
      "\n",
      "- aueavui_a1999m5d8.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 446/891 processed\n",
      "\n",
      "- aueavui_a1999m6d12.pdf\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "- 454/891 processed\n",
      "\n",
      "- aueavui_a1999m6d19.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "- 462/891 processed\n",
      "\n",
      "- aueavui_a1999m6d26.pdf\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "- 470/891 processed\n",
      "\n",
      "- aueavui_a1999m6d5.pdf\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_5.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_8.png OCR✔️ FIX✔️\n",
      "-- page_6.png OCR✔️ FIX✔️\n",
      "-- page_7.png OCR✔️ FIX✔️\n",
      "- 478/891 processed\n",
      "\n",
      "- aueavui_a2002m10d12.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "- 482/891 processed\n",
      "\n",
      "- aueavui_a2002m10d19.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "- 486/891 processed\n",
      "\n",
      "- aueavui_a2002m10d26.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "- 490/891 processed\n",
      "\n",
      "- aueavui_a2002m10d5.pdf\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "- 494/891 processed\n",
      "\n",
      "- aueavui_a2002m11d16.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "- 498/891 processed\n",
      "\n",
      "- aueavui_a2002m11d2.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "- 502/891 processed\n",
      "\n",
      "- aueavui_a2002m11d23.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "- 506/891 processed\n",
      "\n",
      "- aueavui_a2002m11d30.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "- 510/891 processed\n",
      "\n",
      "- aueavui_a2002m11d9.pdf\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "- 514/891 processed\n",
      "\n",
      "- aueavui_a2002m12d14.pdf\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "- 518/891 processed\n",
      "\n",
      "- aueavui_a2002m12d28.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "- 522/891 processed\n",
      "\n",
      "- aueavui_a2002m12d7.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "- 526/891 processed\n",
      "\n",
      "- aueavui_a2002m3d16.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "- 530/891 processed\n",
      "\n",
      "- aueavui_a2002m3d23.pdf\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "- 534/891 processed\n",
      "\n",
      "- aueavui_a2002m3d30.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "- 538/891 processed\n",
      "\n",
      "- aueavui_a2002m3d9.pdf\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "- 542/891 processed\n",
      "\n",
      "- aueavui_a2002m4d13.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "- 546/891 processed\n",
      "\n",
      "- aueavui_a2002m4d20.pdf\n",
      "-- page_1.png OCR✔️ FIX✔️\n",
      "-- page_2.png OCR✔️ FIX✔️\n",
      "-- page_3.png OCR✔️ FIX✔️\n",
      "-- page_4.png OCR✔️ FIX✔️\n",
      "- 550/891 processed\n",
      "\n",
      "- aueavui_a2002m4d27.pdf\n",
      "⚠️Error during API call⚠️: Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': 'Number of request tokens has exceeded your daily rate limit (https://docs.anthropic.com/en/api/rate-limits); see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.'}}\n",
      "-- page_3.png OCR✅ FIX❌\n",
      "⚠️Error during API call⚠️: Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': 'Number of request tokens has exceeded your daily rate limit (https://docs.anthropic.com/en/api/rate-limits); see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.'}}\n",
      "-- page_4.png OCR✅ FIX❌\n",
      "⚠️Error during API call⚠️: Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': 'Number of request tokens has exceeded your daily rate limit (https://docs.anthropic.com/en/api/rate-limits); see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.'}}\n",
      "-- page_2.png OCR✅ FIX❌\n",
      "-- page_1.png OCR✅ FIX✅\n",
      "- 554/891 processed\n",
      "\n",
      "- aueavui_a2002m4d6.pdf\n",
      "⚠️Error during OCR for docs/aueavui/img/aueavui_a2002m4d6.pdf/page_2.png⚠️: (-2, 'Estimating resolution as 175')\n",
      "⚠️Error during API call⚠️: Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': 'Number of request tokens has exceeded your daily rate limit (https://docs.anthropic.com/en/api/rate-limits); see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.'}}\n",
      "⚠️Error during API call⚠️: Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': 'Number of request tokens has exceeded your daily rate limit (https://docs.anthropic.com/en/api/rate-limits); see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.'}}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-42ddb12ab08e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Perform OCR and correction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdo_ocr_and_fix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_correction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# End time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-103-5fef4f7d69c7>\u001b[0m in \u001b[0;36mdo_ocr_and_fix\u001b[0;34m(download_summary, skip_correction)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mfutures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_correction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_tasks\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_completed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                     \u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mocr_status\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfix_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                     \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    238\u001b[0m                             len(pending), total_futures))\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"===========Performing OCR and correction===========\")\n",
    "\n",
    "# Start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Perform OCR and correction\n",
    "do_ocr_and_fix(download_summary, skip_correction=False)\n",
    "\n",
    "# End time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Elapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53ad5d0",
   "metadata": {},
   "source": [
    "### Create sentence segmented corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "55612047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import re\n",
    "import sys\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "END_PUNCS = [\"!\", '.', '?', '.\"', '?\"', '!\"', \"…\", \":\"]\n",
    "DOC_FORMATS = [\".txt\"]\n",
    "\n",
    "def ellipsis_split(text):\n",
    "    text = re.sub('\\.\\.\\.', '…', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    sents = []\n",
    "    currsent = \"\"\n",
    "    split_points = []\n",
    "    sent_begin = 0\n",
    "    for i, c in enumerate(text):\n",
    "        if c == \"…\":\n",
    "            if i+1 < len(text) and text[i+1].islower():\n",
    "                continue\n",
    "            elif i+2 < len(text) and text[i+2].islower():\n",
    "                continue\n",
    "            else:\n",
    "                sents.append(text[sent_begin:i+1])\n",
    "                sent_begin = i + 1\n",
    "        if i == len(text) - 1:\n",
    "            sents.append(text[sent_begin:i+1])\n",
    "    return sents\n",
    "\n",
    "def is_sent(text):\n",
    "    return any(text.endswith(punc) for punc in END_PUNCS) and len(text) > 3 and text[0].isupper() and \"__\" not in text and \"…………\" not in text\n",
    "\n",
    "def clean_sent(text):\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = re.sub(\"^– \", '', text)\n",
    "    text = re.sub(\"^- \", '', text)\n",
    "    text = re.sub(\"^\\(\", '', text)\n",
    "    text = re.sub(\"\\)$\", '', text)\n",
    "    text = re.sub(\"^»[a-z]\\) \", '', text)\n",
    "    return text.strip()\n",
    "\n",
    "def parse_sents(text):\n",
    "    lines_in_text = [t for t in text.split(\"\\n\") if t]\n",
    "    sents = []\n",
    "    \n",
    "    for line in lines_in_text:\n",
    "        sent_candidates = sent_tokenize(line.strip())\n",
    "        clean_sentences = [clean_sent(s) for s in sent_candidates]\n",
    "        sents.extend(clean_sentences)\n",
    "        \n",
    "    return sents\n",
    "\n",
    "def make_corpus(download_summary, general_corpus_path = 'docs/corpus-general.txt', sent_corpus_path = \"docs/corpus-sentences.txt\"):\n",
    "    all_publication_lines = []\n",
    "    complete_sents = []\n",
    "\n",
    "    for pub in download_summary:\n",
    "        print(pub['name'])\n",
    "\n",
    "        fix_dir = os.path.join(pub['directory'], 'fix')\n",
    "        corpus_file_name = f\"{pub['id']}-corpus.txt\"\n",
    "        corpus_path = os.path.join(pub['directory'], corpus_file_name)\n",
    "\n",
    "        all_sents = []\n",
    "\n",
    "        for doc_name in os.listdir(fix_dir):\n",
    "            doc_dir = os.path.join(fix_dir, doc_name)\n",
    "            if not os.path.isdir(doc_dir):\n",
    "                continue\n",
    "\n",
    "            for file_name in os.listdir(doc_dir):\n",
    "                if file_name == '.DS_Store':\n",
    "                    continue\n",
    "\n",
    "                file_path = os.path.join(doc_dir, file_name)\n",
    "                if os.path.splitext(file_name)[1] in DOC_FORMATS:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                        text = file.read()\n",
    "\n",
    "                    sents = parse_sents(text)\n",
    "                    all_sents.extend(sents)\n",
    "                    complete_sents.extend([s for s in sents if is_sent(s)])\n",
    "                    \n",
    "\n",
    "        # Write all sentences to the publication corpus file\n",
    "        with open(corpus_path, 'w', encoding='utf-8') as f:\n",
    "            for sent in all_sents:\n",
    "                f.write(sent + '\\n')\n",
    "\n",
    "        # Add to the general corpus\n",
    "        all_publication_lines.extend(all_sents)\n",
    "\n",
    "        # Print the number of sentences and words for each publication\n",
    "        word_count = sum(len(sent.split()) for sent in all_sents)\n",
    "        print(f\"{len(all_sents)} lines, {word_count} words\")\n",
    "        print(f\"Corpus written to {corpus_path}\")\n",
    "        print(\"------------------------------------\")\n",
    "\n",
    "    # Write the general corpus\n",
    "    with open(general_corpus_path, 'w', encoding='utf-8') as f:\n",
    "        for sent in all_publication_lines:\n",
    "            f.write(sent + '\\n')\n",
    "\n",
    "    # Print the number of sentences and words for the general corpus\n",
    "    general_word_count = sum(len(sent.split()) for sent in all_publication_lines)\n",
    "    print(\"====================================\")\n",
    "    print(f\"General corpus written to {general_corpus_path}\")\n",
    "    print(f\"{len(all_publication_lines)} lines, {general_word_count} words\")\n",
    "    \n",
    "    # Write the sentence-ensured corpus\n",
    "    with open(sent_corpus_path, 'w', encoding='utf-8') as f:\n",
    "        for sent in complete_sents:\n",
    "            f.write(sent + '\\n')\n",
    "            \n",
    "    print(f\"Sentence corpus written to {sent_corpus_path}\")\n",
    "    sentenced_word_count = sum(len(sent.split()) for sent in complete_sents)\n",
    "    print(f\"{len(complete_sents)} lines, {sentenced_word_count} words\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a98b79b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========Generating corpora===========\n",
      "Vielha de toti : era revista dera gent de Vielha e Mijaran\n",
      "265 lines, 6580 words\n",
      "Corpus written to docs/vietot/vietot-corpus.txt\n",
      "------------------------------------\n",
      "Aran un país\n",
      "115 lines, 2927 words\n",
      "Corpus written to docs/arapai/arapai-corpus.txt\n",
      "------------------------------------\n",
      "Aué : suplement setmanau deth diari Avui\n",
      "17630 lines, 209009 words\n",
      "Corpus written to docs/aueavui/aueavui-corpus.txt\n",
      "------------------------------------\n",
      "====================================\n",
      "General corpus written to docs/corpus-general.txt\n",
      "18010 lines, 218516 words\n",
      "Sentence corpus written to docs/corpus-sentences.txt\n",
      "8230 lines, 171474 words\n",
      "Elapsed time: 0.7521059513092041 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"===========Generating corpora===========\")\n",
    "\n",
    "# Start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Perform OCR and correction\n",
    "make_corpus(download_summary)\n",
    "\n",
    "# End time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Elapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd049068",
   "metadata": {},
   "source": [
    "# PIPELINE ENDS HERE\n",
    "\n",
    "Rest of this notebook is for auxiliary tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a15cfd1",
   "metadata": {},
   "source": [
    "## OCR comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5d9fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jiwer\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb27304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate WER and print differences\n",
    "def compare_texts(ocr_text, gold_text):\n",
    "    # Manual transformation to lowercase and strip extra spaces\n",
    "    ocr_text = ocr_text.lower().strip()\n",
    "    gold_text = gold_text.lower().strip()\n",
    "\n",
    "    # Calculate CER\n",
    "    cer = jiwer.cer(gold_text, ocr_text)\n",
    "    \n",
    "    # Print WER\n",
    "    print(f\"Character Error Rate (CER): {cer:.2f}\\n\")\n",
    "    \n",
    "    # Print differences\n",
    "    diff = difflib.ndiff(ocr_text.split(), gold_text.split())\n",
    "    count = 0\n",
    "    diffs_str = \"\"\n",
    "    for line in diff:\n",
    "        if line.startswith('- '):\n",
    "            diffs_str += line[2:] + ' / '\n",
    "        elif line.startswith('+ '):\n",
    "            count += 1\n",
    "            diffs_str += line[2:] + '\\n'\n",
    "            \n",
    "    print(f\"OCR / GOLD ({count}/{len(gold_text.split())}):\")\n",
    "    print(diffs_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d6d2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('docs_play/page_3_haiku.txt', 'r') as f:\n",
    "    postfixed_text = f.read()\n",
    "    \n",
    "with open('docs_play/page_3_sonnet.txt', 'r') as f:\n",
    "    direct_text = f.read()\n",
    "    \n",
    "compare_texts(postfixed_text, direct_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb33f81",
   "metadata": {},
   "source": [
    "## Sketches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed12de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'docs/vietot/img/vietot_a2017n1.pdf/page_6.png'\n",
    "\n",
    "base64_image = image_to_base64(img_path)\n",
    "\n",
    "OCR_text = get_text_from_image_with_api(base64_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fcdec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(OCR_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f051812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def fix_ocr_text_formatting(text):\n",
    "    # Replace hyphenated line breaks with nothing (merge words split by hyphens)\n",
    "    text = re.sub(r'-\\n', '', text)\n",
    "    \n",
    "    # Preserve double line breaks and replace single line breaks within paragraphs with a space\n",
    "#     text = re.sub(r'(?<!\\n)\\n(?!\\n)', ' ', text)\n",
    "    \n",
    "#     # Replace multiple spaces with a single space\n",
    "#     text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "#     # Restore double line breaks as single line breaks\n",
    "#     text = re.sub(r'\\n\\s*\\n', '\\n', text)\n",
    "    \n",
    "    # Strip leading and trailing whitespaces\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61103bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'docs/vietot/img/vietot_a2017n1.pdf/page_6.png'\n",
    "\n",
    "ocr_text = ocr_image_to_text(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8763eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fix_ocr_text_formatting(ocr_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dfb15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('docs_play/page_6_nolang.txt', 'r') as f:\n",
    "    postfixed_text = f.read()\n",
    "    \n",
    "with open('docs_play/page_6_fra.txt', 'r') as f:\n",
    "    direct_text = f.read()\n",
    "    \n",
    "compare_texts(postfixed_text, direct_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba78af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_texts(postfixed_text, direct_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4011b1a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
